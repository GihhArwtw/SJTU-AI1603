{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversial Learning Implementation on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit:** This project is written by Y. Qiu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST Classifier Utilizing CNN\n",
    "### 1.1 Hyperparameters\n",
    "The following block shows the hyperparameters of the CNN model.  \n",
    "1. `learning_rate` indicates learning rate.  \n",
    "2. `batch_size_train` indicates the size of batch of the training dataset since batch processing is introduced to speed up the process.  \n",
    "3. `batch_size_test` indicates the size of batch of the testing dataset since batch processing is introduced to speed up the process. \n",
    "4. `drop_out_rate` indicates the probability at which neurons are dropped out.\n",
    "5. `normalize`,`normalize_mean` and `normalize_std` are three hyperparameters controlling normalization of data preprocessing. `normalize` indicates whether normalize the original data in data preprocessing. When `normalize=True`, apply normalization to the original dataset using the following `normalize_mean` and `normalize_std`, the specific meaning of which will be discussed in **1.3**.  \\\n",
    "   Note that `normalize_mean` and `normalize_std` must be tuples.  \n",
    "6. `optimizer_choice` indicates the choice of optimizer used to optimize the parameters in the network.\n",
    "7. `log_interval` indicates the number of training examples in the interval when logging out the current loss when training.   \n",
    "8. `n_epochs` indicates the number of training epoches.  \n",
    "9. `activation` indicates the activation function used in CNN.  \n",
    "10. `loss_func` indicates the loss function.  \n",
    "11. `loss_func_test` indicates the loss function **without built-in average treatment**, since in the test process we need to accumulate the loss in every batch.  \n",
    "12. `random_seed` indicates the random seed used for repeatable experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "drop_out_rate = 0.5\n",
    "\n",
    "normalize = True\n",
    "normalize_mean = (0.1307,)\n",
    "normalize_std = (0.3081,)\n",
    "                            # those figures are given in the pytorch official website\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "optimizer_choice = Adam\n",
    "\n",
    "log_interval = 100\n",
    "n_epochs = 3\n",
    "\n",
    "from torch.nn import LeakyReLU, CrossEntropyLoss as CEL\n",
    "activation = LeakyReLU(inplace=True)\n",
    "loss_func = CEL()\n",
    "loss_func_test = CEL(reduction='sum')\n",
    "\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Necessary Packages\n",
    "The following block imports several needed packages, mostly packed in **pyTorch**, **Matplotlib**, **Numpy** and **OpenCV.**  \n",
    "- Details are given in the annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                            # necessary in constructing the network.\n",
    "import torchvision                                      # used to download and preprocess the MNIST dataset.\n",
    "from torch.utils.data import DataLoader                 # same as above\n",
    "import torchvision.transforms as tsf                    # same as above, used in data preprocessing.\n",
    "import torch.nn as nn                                   # necessary in constructing the network.\n",
    "import torch.nn.functional as func                      # same as above, providing useful functions.\n",
    "import matplotlib.pyplot as plt                         # used in creating figures and visualizations\n",
    "from PIL import Image                                   # used in testing local pictures\n",
    "import numpy as np                                      # used in some mathemetical operations\n",
    "import time                                             # used for timer\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preparation\n",
    "Data preparation includes two steps: data download and data preprocessing.\n",
    "- Download MNIST dataset using built-in methods in `torchvision`.\n",
    "- Preprocess original data, i.e. normalization and divide datasets into batches.  \n",
    "  According to pyTorch official website,  \n",
    "  \n",
    "$${\\rm Normalize(mean,std)}:  x=\\dfrac{x_{\\text{original}}-\\text{mean}}{\\text{std}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "trans = tsf.ToTensor()\n",
    "if (normalize):\n",
    "    trans = tsf.Compose([tsf.ToTensor(), tsf.Normalize(normalize_mean, normalize_std)])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data/', train=True, download=True, transform=trans),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data/', train=False, download=True, transform=trans),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Network Construction\n",
    "Utilizing `torch.nn` to construct the network.  \n",
    "In this project, we construct a CNN with 3 convolution layers and 3 fully connected layers.  \n",
    "- Details are given in the annotations.  \n",
    "\n",
    "The following block defines a CNN with 3 Conv layers and 3 FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-layer version.\n",
    "\n",
    "class CNN(nn.Module):                  # CNN with 2 Conv layers and 2 FC layers\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d( 1, 8, kernel_size=3, padding=1),              #  1*28*28 -> 8*28*28\n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1),        #  8*28*28 -> 8*28*28 since 28*28 is quite a small size\n",
    "            nn.Conv2d( 8,16, kernel_size=3, padding=1),              #  8*28*28 -> 16*28*28\n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2),                             # 16*28*28 -> 16*14*14\n",
    "            nn.Conv2d(16,32, kernel_size=3),                         # 16*14*14 -> 32*12*12\n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2),                             # 32*12*12 -> 32*6*6\n",
    "            nn.Flatten(1),                                           # 32*6*6   -> 1*1152, i.e. a vector\n",
    "            nn.Dropout(drop_out_rate),\n",
    "            nn.Linear(1152, 288),\n",
    "            activation,\n",
    "            nn.Dropout(drop_out_rate),\n",
    "            nn.Linear( 288,  64),\n",
    "            activation,\n",
    "            nn.Dropout(drop_out_rate),\n",
    "            nn.Linear(  64,  10)\n",
    "        )       # END self.network\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return func.log_softmax(self.network(x), dim=1)                    # Using log_softmax to represent the probability of each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block prepare the optimizer.  \n",
    "For further experiments, we can introduce **StepLR** to better train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "optimizer = optimizer_choice(net.parameters(), lr=learning_rate)\n",
    "\n",
    "#from torch.optim.lr_scheduler import StepLR\n",
    "#step_optimizer = StepLR(optimizer,step_size=50,gamma=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the help of ***Qi Fan***, one of my partner in the groupwork, I learned about the module \"torchsummary\".  \n",
    "Using \"summary\", we can get a more visual glimpse of our network's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "         LeakyReLU-2            [-1, 8, 28, 28]               0\n",
      "         MaxPool2d-3            [-1, 8, 29, 29]               0\n",
      "            Conv2d-4           [-1, 16, 29, 29]           1,168\n",
      "         LeakyReLU-5           [-1, 16, 29, 29]               0\n",
      "         MaxPool2d-6           [-1, 16, 14, 14]               0\n",
      "            Conv2d-7           [-1, 32, 12, 12]           4,640\n",
      "         LeakyReLU-8           [-1, 32, 12, 12]               0\n",
      "         MaxPool2d-9             [-1, 32, 6, 6]               0\n",
      "          Flatten-10                 [-1, 1152]               0\n",
      "          Dropout-11                 [-1, 1152]               0\n",
      "           Linear-12                  [-1, 288]         332,064\n",
      "        LeakyReLU-13                  [-1, 288]               0\n",
      "          Dropout-14                  [-1, 288]               0\n",
      "           Linear-15                   [-1, 64]          18,496\n",
      "        LeakyReLU-16                   [-1, 64]               0\n",
      "          Dropout-17                   [-1, 64]               0\n",
      "           Linear-18                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 357,098\n",
      "Trainable params: 357,098\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 1.36\n",
      "Estimated Total Size (MB): 1.85\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Model Training and Testing Preparation\n",
    "Train the CNN constructed for `n_epoch` epochs and log the loss as it goes.  \n",
    "Also, save the model when training.  \n",
    "The following several block defines the training methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "train_cnt = []\n",
    "\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "test_cnt = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "# Lists used for logging loss and accuracy in training and testing iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch):\n",
    "    model.train()\n",
    "    correct_log = 0\n",
    "    sumnum = 0\n",
    "    \n",
    "    global train_loss\n",
    "    global train_acc\n",
    "    global train_cnt\n",
    "    \n",
    "    for batch, (data, target) in enumerate(train_loader):\n",
    "        batch_idx = batch + 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(1, keepdim=True)\n",
    "        correct_cur = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct_log += correct_cur\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "                            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                            100. * batch_idx / len(train_loader), loss.item(),\n",
    "                            correct_log, log_interval * len(data), 100. * correct_log / (log_interval * len(data)) ))\n",
    "            correct_log = 0\n",
    "            sumnum += len(data) * log_interval\n",
    "        \n",
    "        train_loss += [loss.item()]\n",
    "        train_acc += [correct_cur / len(data)]\n",
    "        train_cnt += [(batch_idx*batch_size_train) + ((epoch-1)*len(train_loader.dataset))]\n",
    "        correct_fig = 0\n",
    "    \n",
    "    if len(train_loader) % log_interval != 0:\n",
    "        print('Train Epoch {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "                                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                                100. * batch_idx / len(train_loader), loss.item(), \n",
    "                                correct_log, len(train_loader.dataset)-sumnum, 100. * correct_log / (len(train_loader.dataset)-sumnum) ))\n",
    "    \n",
    "    torch.save(model, 'model'+str(epoch)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    global test_loss\n",
    "    global test_acc\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            loss += loss_func_test(output, target).item()\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    \n",
    "    loss /= len(test_loader.dataset)\n",
    "    test_loss += [loss]\n",
    "    test_acc += [correct / len(test_loader.dataset)]\n",
    "    \n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(loss, correct, len(test_loader.dataset),\n",
    "                                                                              100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training:\n",
      "Test set: Avg. loss: 2.3010, Accuracy: 1010/10000 (10.10%)\n",
      "\n",
      "During Training:\n",
      "Train Epoch 1 [6400/60000 (11%)]\tLoss: 0.433254\t Accuracy: 4279/6400 (66.86%)\n",
      "Train Epoch 1 [12800/60000 (21%)]\tLoss: 0.431017\t Accuracy: 5731/6400 (89.55%)\n",
      "Train Epoch 1 [19200/60000 (32%)]\tLoss: 0.152698\t Accuracy: 5907/6400 (92.30%)\n",
      "Train Epoch 1 [25600/60000 (43%)]\tLoss: 0.257842\t Accuracy: 5937/6400 (92.77%)\n",
      "Train Epoch 1 [32000/60000 (53%)]\tLoss: 0.173656\t Accuracy: 5967/6400 (93.23%)\n",
      "Train Epoch 1 [38400/60000 (64%)]\tLoss: 0.503042\t Accuracy: 6039/6400 (94.36%)\n",
      "Train Epoch 1 [44800/60000 (75%)]\tLoss: 0.360331\t Accuracy: 6099/6400 (95.30%)\n",
      "Train Epoch 1 [51200/60000 (85%)]\tLoss: 0.153391\t Accuracy: 6076/6400 (94.94%)\n",
      "Train Epoch 1 [57600/60000 (96%)]\tLoss: 0.139074\t Accuracy: 6061/6400 (94.70%)\n",
      "Train Epoch 1 [30016/60000 (100%)]\tLoss: 0.477194\t Accuracy: 2271/2400 (94.62%)\n",
      "\n",
      "Test set: Avg. loss: 0.0782, Accuracy: 9754/10000 (97.54%)\n",
      "\n",
      "Train Epoch 2 [6400/60000 (11%)]\tLoss: 0.201862\t Accuracy: 6045/6400 (94.45%)\n",
      "Train Epoch 2 [12800/60000 (21%)]\tLoss: 0.093555\t Accuracy: 6090/6400 (95.16%)\n",
      "Train Epoch 2 [19200/60000 (32%)]\tLoss: 0.234914\t Accuracy: 6087/6400 (95.11%)\n",
      "Train Epoch 2 [25600/60000 (43%)]\tLoss: 0.228603\t Accuracy: 6121/6400 (95.64%)\n",
      "Train Epoch 2 [32000/60000 (53%)]\tLoss: 0.313574\t Accuracy: 6130/6400 (95.78%)\n",
      "Train Epoch 2 [38400/60000 (64%)]\tLoss: 0.117175\t Accuracy: 6123/6400 (95.67%)\n",
      "Train Epoch 2 [44800/60000 (75%)]\tLoss: 0.234196\t Accuracy: 6114/6400 (95.53%)\n",
      "Train Epoch 2 [51200/60000 (85%)]\tLoss: 0.256066\t Accuracy: 6133/6400 (95.83%)\n",
      "Train Epoch 2 [57600/60000 (96%)]\tLoss: 0.378354\t Accuracy: 6161/6400 (96.27%)\n",
      "Train Epoch 2 [30016/60000 (100%)]\tLoss: 0.203842\t Accuracy: 2291/2400 (95.46%)\n",
      "\n",
      "Test set: Avg. loss: 0.0709, Accuracy: 9814/10000 (98.14%)\n",
      "\n",
      "Train Epoch 3 [6400/60000 (11%)]\tLoss: 0.124538\t Accuracy: 6139/6400 (95.92%)\n",
      "Train Epoch 3 [12800/60000 (21%)]\tLoss: 0.169738\t Accuracy: 6148/6400 (96.06%)\n",
      "Train Epoch 3 [19200/60000 (32%)]\tLoss: 0.268883\t Accuracy: 6132/6400 (95.81%)\n",
      "Train Epoch 3 [25600/60000 (43%)]\tLoss: 0.034606\t Accuracy: 6165/6400 (96.33%)\n",
      "Train Epoch 3 [32000/60000 (53%)]\tLoss: 0.385198\t Accuracy: 6163/6400 (96.30%)\n",
      "Train Epoch 3 [38400/60000 (64%)]\tLoss: 0.216390\t Accuracy: 6135/6400 (95.86%)\n",
      "Train Epoch 3 [44800/60000 (75%)]\tLoss: 0.146573\t Accuracy: 6132/6400 (95.81%)\n",
      "Train Epoch 3 [51200/60000 (85%)]\tLoss: 0.046650\t Accuracy: 6128/6400 (95.75%)\n",
      "Train Epoch 3 [57600/60000 (96%)]\tLoss: 0.362410\t Accuracy: 6107/6400 (95.42%)\n",
      "Train Epoch 3 [30016/60000 (100%)]\tLoss: 0.127482\t Accuracy: 2301/2400 (95.88%)\n",
      "\n",
      "Test set: Avg. loss: 0.0540, Accuracy: 9853/10000 (98.53%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Training:\", end=\"\")\n",
    "test(net, test_loader)\n",
    "\n",
    "print(\"During Training:\")\n",
    "for epoch in range(n_epochs):\n",
    "    train(net, optimizer, train_loader, epoch+1)\n",
    "    test(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Plot Depictng Loss and Accuracy Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax1 = plt.subplot()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(train_cnt, train_loss, color='#ff9999')\n",
    "#ax1.scatter(test_cnt, test_loss, color='red')\n",
    "ax1.legend(['Train Loss'], loc='lower right')\n",
    "ax1.set_ylabel('Cross Entropy Loss')\n",
    "\n",
    "ax2.plot(train_cnt, train_acc, color='#7e9ecd')\n",
    "ax2.legend(['Accuracy'], loc='upper right')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Model Loading and Local Sample Testing\n",
    "In the first following block, the former model constructed, trained, and saved will be loaded.  \n",
    "In the second block, some tests from the original MNIST dataset are extracted to test the loaded model.  \n",
    "In the third block, some local samples are given to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model'+str(n_epochs)+'.pth')\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAELCAYAAAARNxsIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAefklEQVR4nO3deZRUxd3/8c9XdkRFlCg7Aq4BVHBJFAURBTWouOESo4YYNajhZ3A7QkwEH5eYgI9RURRQjo8ri+aJwbjEDRPUQTRuBEhAGB5QEFSQgGD9/uj25taVbrp7qnt6pt+vc+ac+k7de7ump2a+c6tq6ppzTgAAhLBdbTcAAFB/kFQAAMGQVAAAwZBUAADBkFQAAMGQVAAAwdT5pGJmU8xsbLp8hJnNL/A6E8xsdNjWoZzRd1Ao+k5mJUkqZrbYzDaY2TozW2lmk82sRejXcc694pzbO4f2nG9mrybOvdg5NyZ0m7by2mea2Xwz+8zMPjazB8xsx2K/bl1F3/Fe+zwzqzKzz81smZndamYNi/26dRV951uv///MbEX6d88kM2tSjNcp5Z3KYOdcC0m9JB0saVTygAr5AZkt6XDn3E6SukhqKGls7Tap7NF3UppLGiFpV0mHSjpa0sjabFAdQN+RZGYDJV2jVJ/prNTvnl8X47VKPvzlnKuW9CdJ3SXJzJyZDTezBZIWpD/3AzObZ2Zrzew1M+v5zflmdqCZzTWzL8zsUUlNY3X9zGxZLO5gZtPN7BMzW21mvzezfSVNkPT99F8wa9PHRrez6fhCM1toZp+a2VNm1jZW58zsYjNbYGZrzOxOM7Mcv/6lzrlVsU9tkdQtj7ewYtF33N3pv4o3pd+LhyQdXsBbWXEqve9IOk/S/c6595xzaySNkXR+fu9ibkqeVMysg6TjJb0V+/TJSv3ltZ+Z9ZI0SdJFknaRdI+kp8ysiZk1ljRT0lRJrSQ9LunUDK/TQNL/SlqiVGZuJ+kR59wHki6W9FfnXAvnXMutnNtf0k2SzpDUJn2NRxKH/UCpv3z2Tx83MH1ux3Sn7JjlPehjZp9J+iLd/vGZjsV/0He+5UhJ7+V4bEWj7+i7kt6OxW9L2s3MdslwfOGcc0X/kLRY0jpJa5V6o+6S1Cxd5yT1jx17t6QxifPnS+qr1A/RckkWq3tN0th0uZ+kZeny9yV9IqnhVtpzvqRXE5+bErvO/ZJujdW1kPSVpM6xNveJ1T8m6ZoC3pd2kn4laa9SfB/q4gd9J+P7coGkZZJ2re3vUbl+0He811kkaVAsbpS+XufQ73spxxJPds49l6FuaazcSdJ5ZnZZ7HONJbVV6k2odul3JW1Jhmt2kLTEObe5gLa2lTT3m8A5t87MViuVBBanP70idvyXSnWAvDjnqs1sllJ/jfQqoJ2Vgr4TY2YnS7pZ0gDnD6Xi2+g7KeskxRcEfVP+ooB2ZlUuS4rj36ylkm50zrWMfTR3zj0s6f8ktUuMI2a63VsqqaNtfRJuW1szL1eqk0mSzGx7pW6Jq7f1hRSgoaSuRbhupaiovmNmgyRNVGoC+u8hrlnBKqnvvKfUkNk39pe00jm3OsC1PeWSVOImSrrYzA61lO3N7AQz20HSXyVtlnS5mTU0s1MkHZLhOq8r1RluTl+jqZl9M6m5UlL79Fjp1vyPpAvM7ABLLbv7L0lznHOLa/rFmdk56fFPM7NOkm6U9HxNrwtJ9b/v9Fdqcv5U59zrNb0ePPW670h6UNIwM9vPzHZWahXclADX/ZaySyrOuTclXSjp95LWSFqo9CoF59wmSaek4zWShkqanuE6WyQNVmpl1UdKjT8PTVe/oFTmXmFm3xo+cM49L2m0pGlKdZCuks7Mpf3phLEuy4TZfkqNx65Tannx/PTXixqqgL4zWtJOkp5OH7fOzP6Uy7WRXX3vO865WZJulfQXpYbulki6Ppdr58v8YUIAAApXdncqAIC6i6QCAAiGpAIACIakAgAIhqQCAAgmr/+oNzOWipUh51yum8rVCvpN2VrlnGtd243Ihr5TtjL2He5UgMqVaasRYFsy9h2SCgAgGJIKACAYkgoAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACCYUj6jHqg1P/3pT6PyqFGjvLp27doVfN0///nPUfnll1/26qqqqjIeC9RX3KkAAIIhqQAAgiGpAACCyesZ9ewYWp7Ypfjb9tlnHy9+/vnno/Juu+1WlNc0878NmzZt8uIpU6ZE5UsuuaQobchTlXPuoNpuRDZ17XfO0KFDo/LDDz/s1SX7R/x376xZs7y6wYMHe/GWLVtCNTGUjH2HOxUAQDAkFQBAMCwpRr10yCGHeHGxhryyadSokRefc845UXmPPfbw6n74wx9G5VWrVhW3YShY9+7dvfjKK6/04lNOOSUqJ6cWsk01DBw40IufeeYZL37wwQej8jvvvOPVzZs3L3ODawF3KgCAYEgqAIBgSCoAgGDKfk4lOS693377ReUmTZp4deeff74X9+jRIyrvtddeXl1yeV/r1q2jcnIp4Nlnn517g1EWPvroIy9et25dVG7RokWpmyNJat68eVQeMGCAV9e5c+eozJxKeWnbtm1UvuWWW7y6QYMGFeU1jzrqqIzx5s2bvbqf//znUXnSpEleXXJZeylwpwIACIakAgAIplaGv4477jgvPvHEE6Nyz549vbrGjRt7ca9evYrSpq+//joqJ4cmksMl8aEUlKcXX3zRi6dNmxaV27dvn/N14sOtktSmTZsatQvlr1mzZl48c+bMqNy7d++s58aXDceHpSTpww8/zHhet27dvPjoo4/24j59+kTl5PL4O++8Myon2z5u3Lis7S0G7lQAAMGQVAAAwZBUAADBlGyX4tdffz0qH3jggV7ddtuVd27797//7cXx+Zcf/ehHXt2MGTNK0qY4dikunuScSnI8+8c//nFUTi49z/aztWbNGi/u27dvVH7//ffzbmeB2KV4K+bPn+/FyfmOuOSS3fju0/FdqWtqp512isoffPCBVxfvk6+88opX169fv2BtSGCXYgBA8ZFUAADBkFQAAMGU7P9UVqxYEZVDzaEkxz5XrlzpxUceeWTO14rPhRxxxBFe3a677prxvKVLl+b8Gqh7kvMbyTj5P025eumll7JeF8W1/fbbR+Xk74nvfOc7Gc9LbpFy++23e3HIeZS4zz77LCpnewrkYYcd5sXJbWWuvvrqsA3bCu5UAADBkFQAAMGUbPgrvtzyrLPO8ur+8Ic/ROXk7WU2GzZs8OLk8r74MrxtWb16dVRO7nZ83333ZTyvuro659dA3ZdcUnzCCScUdJ0nnngiRHNQoPj3LbkreTb33HOPF19zzTXB2pSrr776KmNdgwYNvDg5HFYK3KkAAIIhqQAAgiGpAACCKdmcSny7+IkTJ5bkNfN5gl58e/shQ4YUozmog1q2bOnFzzzzjBd3794952vNmTMn43VQXLvvvrsXjx49uqDrPPnkkyGaUyOTJ0/24l/96le105AMuFMBAARDUgEABENSAQAEUyuPEy4HTZo08eLHHnssKg8cONCrS25hftNNN0Xljz/+uAitQ7lIzq/lM4eSFN9WKLn1PYrr2GOP9eLkIw2yueuuu6Lyyy+/HKxNhcqnDya3yS8F7lQAAMGQVAAAwdTr4a/4bsjJnYdHjhzpxckhr7hJkyZ5caHLEVE3TJ8+PSqfdNJJOZ+X3H37jTfe8OIRI0bUqF2oHc8++2xUzrZFSqnks/XKvvvuW8SWbB13KgCAYEgqAIBgSCoAgGDKfk6lUaNGXnzcccdF5c6dO3t1Rx99tBfvueeeUXnvvfcuuA0nnniiFx9++OE5nZfcFnvWrFleXA7js5WoQ4cOXvyzn/3Mi48//vionFxOns3XX3/txfG+Kkmff/55ztcC4jp16hSV40+tLEfcqQAAgiGpAACCIakAAIIpuzmVVq1aefHChQu9OJ9HBIfSunXrrHEmM2fO9OK///3vXhxfb/7ll18W1jjkpGPHjlE5+X3p2bNnwdedO3duVD755JO9OrZiqZuSc1/vvPNOLbXkPw444IConM/vwNmzZxehNdlxpwIACIakAgAIpuyGv/bYYw8vbtq0acHXmjZtWlResGCBVxffiqMmzj33XC+OL/c7/fTTvboePXp48VVXXRWVy+3pbfVN/PtUk+GuzZs3e3F8x+rly5cXfF0UV/LfArKJP6VWkhYvXhy4NduWXDbcp0+fnM7buHGjF48bNy5Ym3LFnQoAIBiSCgAgGJIKACCYsptTqaqq8uIBAwZ4ce/evaPyW2+95dXNmTPHi+Pj3/lst5GPZHvj+vbt68U77LCDF+e6NBnbltx65cwzz/Ti5JY5uUqOUScfmTBjxoyCrovSSm6RlHyiZ7lJzi1fccUVOZ03ceJEL165cmWwNuWKOxUAQDAkFQBAMCQVAEAwZTenkvTaa69ljctNfCy/Xbt2tdiSypLcemX//fcPct3klh3JObRDDjkk52tdffXVUTk5v5aP+P9fvfnmm15dtjm+SrZp06babkJerrvuuoLOK4evkzsVAEAwJBUAQDCWz1JbMyvOutw6LLl09YEHHojKDRv6o4sfffSRFx9xxBFRedmyZQW3wTlnBZ9cAsXqN6eeempUfuihh7y65HtfCmb+t6FYy9jj1q9f78VdunTx4tWrV2c7vco5d1D4VoUTqu80b97ci+M/izvvvLNXl3yCZ7yfPfXUUyGaI8nfOXvMmDFe3TnnnOPFyb4VF3+CbPxfLiTpvffeq0kTs8nYd7hTAQAEQ1IBAARDUgEABFP2S4rLQXI89sILL4zK8a3PJX8sf9GiRV7d2LFjvbgm8yiQ9tprr6hcG3Mo5WC77fy/C9u0aePF25hTqRjJJ6vG5yyefvppry75nk6YMCEqJ+dF582bl3MbDj30UC9+8MEHo3K3bt1yvs6//vUvL47PxxRxDiVn3KkAAIIhqQAAgmFJcVqLFi2icvLJgKNHj/biY489NuN14v+BfdFFF3l1jz32WE2amFGlLimOL5989tlnvbodd9yxGC+ZVU2WFMd31E4O1WQT/+96yR+azUHFLClOaty4cVS+7bbbvLrhw4dnPC+56+9vf/vbjMcmdylP7rjepEmTjOcm+84HH3wQlY8//nivbunSpRmvU0QsKQYAFB9JBQAQDEkFABBMnZ5Tad++vRfns0Q31PK+5Fj+sGHDonJ1dXXO16mJSp1TiUtuT5Ecvx4xYkRULtYTN5NzKr/+9a+9OPkUybglS5ZE5UceeSRswzKr2DmVbMaPH+/Fl112WdFfM7n0++677/bi66+/vuhtyBNzKgCA4iOpAACCIakAAIIp+zmV5JYJ99xzT1Tu0KGDV5ec3zjjjDOicnJ76+R8THzN+JYtW7y6l19+2YtvvPHGqPzKK694dfH/NygV5lRQIOZUtqJRo0ZePHDgwKh83HHHeXXHHHOMF3ft2jXjdT/88EMvnj59elSeOHGiV5fcDqYMMacCACg+kgoAIJiyH/5q166dFxfrtnDx4sVR+dprr/XqirW9SigMf6FADH+hUAx/AQCKj6QCAAiGpAIACKbsH5e3fv16L45vZ9GpU6es57777rtRecaMGV5dfDmfJC1fvjwqr1q1Ku92AgC4UwEABERSAQAEQ1IBAART9nMqa9eu9eIuXbrUTkMAANvEnQoAIBiSCgAgGJIKACAYkgoAIBiSCgAgGJIKACCYfJcUr5K0ZJtHoZSy71VTHug35Ym+g0Jl7Dt5PU8FAIBsGP4CAARDUgEABENSAQAEQ1IBAARDUgEABENSAQAEQ1IBAARDUgEABENSAQAEQ1IBAARDUgEABENSAQAEQ1IBAART55OKmU0xs7Hp8hFmNr/A60wws9FhW4dyRt9Boeg7mZUkqZjZYjPbYGbrzGylmU02sxahX8c594pzbu8c2nO+mb2aOPdi59yY0G3aymt3N7NnzGyVmfHcgW2g73iv3cTMxpnZcjNbY2Z3mVmjYr9uXUXfydiOF8zMmVm+z9PKSSnvVAY751pI6iXpYEmjkgcU64ssM19JekzSsNpuSB1C30m5RtJBkrpL2kup9+Nb7wU89J0YMztH+T+cMS8lH/5yzlVL+pNSPxhKZ8zhZrZA0oL0535gZvPMbK2ZvWZmPb8538wONLO5ZvaFmT0qqWmsrp+ZLYvFHcxsupl9Ymarzez3ZravpAmSvp/+C2Zt+tjodjYdX2hmC83sUzN7yszaxuqcmV1sZgvSfzHeaWaW49c/3zl3v6T3Cnn/Klml9x1JgyX9t3PuU+fcJ5L+W9KP83wbKxJ9RzKznSRdL+mqPN++vJQ8qZhZB0nHS3or9umTJR0qaT8z6yVpkqSLJO0i6R5JT1nq1r+xpJmSpkpqJelxSadmeJ0Gkv5XqUeRdpbUTtIjzrkPJF0s6a/OuRbOuZZbObe/pJsknSGpTfoajyQO+4FSf/nsnz5uYPrcjulO2THX9wS5oe/I0h/xuH36lwWyoO9Ikv5L0t2SVmQ5puacc0X/kLRY0jpJa5V6o+6S1Cxd5yT1jx17t6QxifPnS+or6UhJy5V+DHK67jVJY9PlfpKWpcvfl/SJpIZbac/5kl5NfG5K7Dr3S7o1VtdCqWGrzrE294nVPybpmjzfk26pt7/4739d/qDveK8zVtJsSa0l7S5pTvp6bWr7+1SOH/Qd73UOkjRPqaGvzulrfauNIT5KOZZ4snPuuQx1S2PlTpLOM7PLYp9rLKmtUm9EtUu/S2lLMlyzg6QlzrnNBbS1raS53wTOuXVmtlqpvzoWpz8dz/ZfKtUBUBz0nZQbJbVU6pfDRkkTJR0o6eMC2lkpKr7vmNl2SiXUnzvnNucxYlaQcllSHP9mLZV0o3OuZeyjuXPuYUn/J6ldYhwx0+3eUkkdbeuTcNtadbVcqU4mSTKz7ZW6Ja7e1heCkquYvuOc2+Ccu9Q5184510XSaklVzrktNb12haqUvrOjUncqj5rZCklvpD+/zMyOqOG1v6VckkrcREkXm9mhlrK9mZ1gZjtI+qukzZIuN7OGZnaKpEMyXOd1pTrDzelrNDWzw9N1K5Uai26c4dz/kXSBmR1gZk2UGouc45xbXNMvLv01NVXqryCl29WkpteFpPrfd9qZWdv01/Y9SaOVmnhFzdXnvvOZUndBB6Q/jk9/vrdSQ6hBlV1Scc69KelCSb+XtEbSQqXGIuWc2yTplHS8RtJQSdMzXGeLUqtlukn6SNKy9PGS9IJSq69WmNmqrZz7vFI/sNOU6iBdJZ2ZS/vTE2brskyYdZK0Qf9Z/bVBqbFb1FAF9J2uSo3lr5f0gFLj6X/O5drIrj73HZey4psPpeZ8JGll+msLyvxhQgAACld2dyoAgLqLpAIACIakAgAIhqQCAAiGpAIACCav/6g3tmovS8654v6LbA3Rb8rWKudc69puRDb0nbKVse9wpwJUrkxbjQDbkrHvkFQAAMGQVAAAwZBUAADBkFQAAMGQVAAAwZBUAADBkFQAAMGQVAAAwZBUAADBkFQAAMGQVAAAwZBUAADB5LVLcaW4/fbbvfjyyy/34j333DMqL1y4sCRtAoC6gDsVAEAwJBUAQDAMf21Fnz59vPjrr7+upZYAQHadO3eOyrfeeqtX179/fy+OD92vWbOmKO3hTgUAEAxJBQAQDEkFABAMcyppjRs3jsoNGjSoxZagtsX7wrBhw7y6ww47zIsPOuigqNy2bVuv7vHHH/fia6+9Nip/8sknNW4nKlOzZs28+He/+11UPumkk7y6W265xYuLNY8Sx50KACAYkgoAIBiGv9KOOeaYqNyjR49abAlK7dxzz/XiUaNGReVu3bp5dWbmxc65jNe94IILvHiXXXaJykOGDMm7najbmjRp4sV77LFHVB4wYIBXN3XqVC/+7LPPovK9997r1cWHvKqqqry63/zmN4U1tga4UwEABENSAQAEQ1IBAATDnEraCSecUNtNQIlccsklXjxu3DgvbtSoUcZz169f78XV1dVROT5nIkmtWrXy4hNPPDGvdqJu69KlixfffPPNXnzqqadmPDe+VF2S7rjjjqh82mmnZTzvuuuu8+JSLCFO4k4FABAMSQUAEAxJBQAQDHMqaQceeGBtNwFFFP+fkfHjx3t1DRv6PwbxRx1Mnz7dq/vlL3/pxfPnz4/K3/ve97y62bNnZ2zPoEGDvHjWrFkZj0XdEd+GPjmHkpwL+eKLL6LyX/7yF68uvqWPJL366qtROfn/Lm+99VZUfvbZZ/NrcBFwpwIACIakAgAIpmKHv3r27OnFye04UL/ccMMNUTk53JUU3/X16quvzvk1Vq1alfOxyeXHqJuSO1PPnDkzKie3e4oPd0nSXXfdFZWTw6qXXnqpF8e3dEkua4/37XLAnQoAIBiSCgAgGJIKACCYiplT2WGHHbw4OVae3FIjLrk0dMWKFeEahqK48847vbh9+/ZRObld/QMPPODF+cyjZJPcJj/XOpSvffbZx4uTS8E7dOgQld9//32vbsSIEV78/PPPR+X4UmRJuu2227x448aNUfknP/mJV/fkk09mb3SJcacCAAiGpAIACIakAgAIpmLmVHr16uXFZ555ZsZjP/30Uy8eM2aMF69bty5cw1AUyTHq+DxKck6lJo9cHThwYFR++OGHM75mUrY6lK+JEyd6cXwOJWnatGleHJ9DSbryyiuzvu6UKVOi8qOPPpr12NrGnQoAIBiSCgAgmIoZ/urYsWPOx7700kteXA47fyK7li1bevGRRx6Z8di3337bixcsWFDw6w4dOjQq77TTTjmfN2TIEC+O74a8YcOGgtuD8OJLzPv06ePVff75514c3+38n//8Z9brxrdXST6NNPlvDMn6csadCgAgGJIKACAYkgoAIJiKmVM599xzcz526tSpRWwJiqFBgwZe3Lx584zHdu3a1YuT822LFi3KeG5yqfLpp5+eYwt9u+22mxd/9dVXBV0H4TVr1syLzz777KicXAretGlTL44/oTEpuTXPrrvumvG6yX+B6N27d1SuqqrK+BrlgDsVAEAwJBUAQDAkFQBAMPV6TqV79+5R+eCDD856bHz78+eee65obUJxJB/V+uabb3px/PvfokULr+7pp5/24j/+8Y9ROTl+nXwMdba5m2zmzZvnxZs3by7oOii+uXPnRuXkY8eTcyrJubK45JxKfB5l9erVXt3kyZO9eFv/81JOuFMBAARDUgEABGP57JZqZnVqa9X77rsvKl9wwQVZjz3ssMOi8pw5c4rWpmJwzpX1YwRro98kv9+TJk2KyjXZITjbEMa2VFdXR+Vsu9uWUJVz7qDabkQ25fY7Jz6kLklt2rTJeGz//v29OPlE0XjfGT58uFc3YcKEQptYKhn7DncqAIBgSCoAgGBIKgCAYOr1kuJsy/tWrlzpxcklfajbkksyGzVqFJWvv/56r2733Xcv+HWyzakklwmPGjWq4NdBeXj33XezxnEjR47Meq133nknKteBOZSccacCAAiGpAIACIakAgAIpl7NqXz3u9/14n79+mU89qGHHvLihQsXFqNJKBP33ntvVJ4xY4ZXl3xEbHIrlrjkfEw2yW3Q41sBoX4aNGhQVM72SGvJ75P1CXcqAIBgSCoAgGDq9DYtrVq18uInnnjCi/v27RuVV6xY4dUdddRRXvyPf/wjcOtKh21aimefffbx4vfff9+L4z8/a9eu9eqOOeYYL47vdlsm2KalhuJL1SXphRdeiMrxrZ8k6W9/+5sXx38/1cFdqtmmBQBQfCQVAEAwJBUAQDB1eklx27ZtvTg+RpmUnH958cUXvfiWW26JyrfffnvNG4d64bTTTsv52DfeeMOLy3AOBYFdeumlXpycR4kbN26cF9fBeZSccKcCAAiGpAIACKZOD3/94he/yPnYxo0be/HGjRu9eObMmSGahHpg8ODBUfmGG27w6pJPfozvxHDVVVcVt2EoO6effroXx/vH1KlTvbrkvzzUV9ypAACCIakAAIIhqQAAgqlzcyrdunWLymeffXbO582ePduLBw4c6MUbNmyoWcNQZzVt2tSLzzvvvKi8rW2M5s+fH5XjT/JD/XTWWWd5cY8ePbx406ZNUTn5bwuVgjsVAEAwJBUAQDAkFQBAMHVuTmXRokVReeTIkV7d+PHjvfi2226Lytddd51XV1+3SED+hg8f7sVDhgzJeOyCBQu8eNiwYUVpE8rTFVdc4cXNmzf34vvvvz8qT548uSRtKjfcqQAAgiGpAACCqXPDX/ElnnfccYdXl4yBXPTu3TvnY6dPn+7FH3/8cejmoIztvPPOXlxVVeXF8Sc/ViruVAAAwZBUAADBkFQAAMHUuTkVILRddtklY92kSZO8+Nprry12c1DG4ttEYeu4UwEABENSAQAEQ1IBAATDnAoqXvIxCAAKx50KACAYkgoAIBiSCgAgGJIKACAYkgoAIBiSCgAgmHyXFK+StKQYDUHBOtV2A3JAvylP9B0UKmPfsfjzSQAAqAmGvwAAwZBUAADBkFQAAMGQVAAAwZBUAADBkFQAAMGQVAAAwZBUAADBkFQAAMH8f3WWkk3FKZukAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "with torch.no_grad():\n",
    "    output = model(example_data)\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(\n",
    "        output.argmax(1, keepdim=True)[i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block loads two local test samples, which are intersting since the former one is highly likely been mistaken for $\"5\"$ and $\"8\"$ respectively by the model trained above.  \n",
    "However, the first sample is designed with the purpose to see whether the model would recognize it as $\"0\"$ or $\"6\"$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('0.png')\n",
    "re_img = torch.Tensor([[np.asarray(img.convert('L'))]])\n",
    "plt.imshow(img, cmap='gray', interpolation='none')\n",
    "\n",
    "output = model(re_img)\n",
    "\n",
    "plt.show()\n",
    "print(\"Prediction:\",output.argmax(1, keepdim=True).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 8\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('5.png')\n",
    "re_img = torch.Tensor([[np.asarray(img.convert('L'))]])\n",
    "plt.imshow(img, cmap='gray', interpolation='none')\n",
    "\n",
    "output = model(re_img)\n",
    "\n",
    "plt.show()\n",
    "print(\"Prediction:\",output.argmax(1, keepdim=True).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adversarial Attack\n",
    "### 2.1 FGSM Attack\n",
    "**FGSM** (Fast Gradient Sign Method) is a classic method to add specifically generated noise to the original data when knowing the inner structure of the model s.t. the generated adversial samples can tempt the model to misktake them for incorrect categories.  \n",
    "Its main idea can be represented as following equations.\n",
    "\n",
    "$$ \\widetilde{x}=x+$$\n",
    "\n",
    "$$=  \\cdot{\\rm sign}(_x J(,x,y))$$  \n",
    "where $$ is the generated noise, $$ is a hyperparameter to control the range of the perturbation, $$ is the parameters of the attacked model, $\\widetilde{x}$ is the adversial sample generated, $x$ is the input, $y$ is the label, $J(,x,y)$ is the loss function used in the attacked model.  \n",
    "#### 2.1.1 Hyperparameters\n",
    "The only hyperparameter is $$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 FGSM Definition\n",
    "The following blocks define the FGSM function and test the original model on FGSM-generated perturbation samples.\n",
    "- The FGSM function generates adversial samples (or perturbations) based on original data, $$ and $_x J(,x,y)$.\n",
    "- FGSM_test applies FGSM attack on the model fed in as inputs and test the model on adversial samples generated.  \n",
    "\n",
    "Details are given in the annotations.\n",
    "\n",
    "**Notice:**\n",
    "- Since we normalize the test data when loading the test dataset, here we clamp the perturbation into $[min,max]$ instead of $[0,1]$.\n",
    "- In this case, the original $$ does not actually represent the range of perturbation. The true range perturbation should relate to both $$ and $|max-min|$, i.e. the real $_{perturbation}$ used should be $\\cdot |max-min|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive FGSM, used when the range of all input data is [0,1]\n",
    "def FGSM_naive(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * data_grad.sign()\n",
    "    pert = torch.clamp(pert, 0, 1)\n",
    "    return pert\n",
    "\n",
    "# Advanced FGSM, used when the dataset is already normalize in the data preprocessing.\n",
    "def FGSM_ad(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * data_grad.sign()\n",
    "    pert = torch.clamp(pert, input_data.min(), input_data.max())\n",
    "    return pert\n",
    "\n",
    "# Our FGSM, regarding epsilon fed in as a coefficient instead of the true range of perturbation.\n",
    "universal_max = 1\n",
    "universal_min = 0\n",
    "if normalize:\n",
    "    universal_max = (universal_max - normalize_mean[0]) / normalize_std[0]\n",
    "    universal_min = (universal_min - normalize_mean[0]) / normalize_std[0]\n",
    "\n",
    "def FGSM(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * (universal_max - universal_min) * data_grad.sign()\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_test(model, test_loader, epsilon, FGSM):\n",
    "\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    for data_batch, target_batch in test_loader:    # Batch Processing\n",
    "        for i in range(data_batch.size()[0]):\n",
    "            data, target = data_batch[i].unsqueeze(0), target_batch[i].unsqueeze(0)\n",
    "            data.requires_grad = True\n",
    "            output = model(data)                                     # Output before FGSM Attack\n",
    "            fore_pred = output.data.max(1, keepdim=True)[1]\n",
    "            if fore_pred.item() != target.item(): continue          # Already failed prediction, discard\n",
    "\n",
    "            loss = loss_func_test(output, target)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            data_grad = data.grad.data\n",
    "            pert = FGSM(data, epsilon, data_grad)                    # FGSM Attack\n",
    "\n",
    "            output = model(pert)\n",
    "            post_pred = output.max(1, keepdim=True)[1]              # Output after the FGSM Attack\n",
    "            if post_pred.item() == target.item():\n",
    "                correct += 1\n",
    "            else:\n",
    "                if len(adv_examples) < 5:\n",
    "                    example = pert.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                           # Preparation for the following visualization, taking eps=0 into account\n",
    "                example = pert.squeeze().detach().cpu().numpy()\n",
    "                adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "\n",
    "    final_acc = correct/(float(len(test_loader.dataset)))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {:.2f}%\".format(epsilon, correct, len(test_loader.dataset), final_acc*100.))\n",
    "\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    start = time.time()\n",
    "    acc, expl = FGSM_test(model, test_loader, eps, FGSM)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Visualization of Adversial Samples\n",
    "The following visualization is based on the code given at https://pytorch.org/tutorials/beginner/fgsm_tutorial.html?highlight=fgsm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fgsm_acc = accuracies\n",
    "\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, accuracies, color='#ff9999', linewidth=3)\n",
    "#ax1.scatter(test_cnt, test_loss, color='red')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PGD\n",
    "**PGD** is so far the most powerful 1-level attack methods. It can be viewed as **i-FGSM** (iteration-FGSM, i.e. using FGSM to attack the model for several rounds) with step $$ and a random noise initialization in each iteration.  \n",
    "Also, in each iteration, we need to clamp the generated noise in $[-,]$.  \n",
    "The main idea of PGD attack can be represented as following equations.  \n",
    "\n",
    "$$x^{t+1}=_{x+S}(x^t+sign(_x J(,x,y))) $$\n",
    "\n",
    "$$\\widetilde{x}=x^{k}$$\n",
    "\n",
    "where $x^{t}$ indicates the sample generated after $t$ iterations, $k$ is the number of attack iterations, $$ is the parameters of the attacked model, $x$ is the original input, $y$ is the label, $J(,x,y)$ is the loss function used in the attacked model.  \n",
    "\n",
    "#### 2.2.1 Hyperparameters\n",
    "Hyperparameters of PGD attack includes $$, the step of single-attack (i.e. FGSM attack), $$, the control of max perburtation, and $k$, steps, i.e. the number of attack iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "steps = 5\n",
    "epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "alphas = np.divide(epsilons, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. PGD Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(model, test_loader, k, alpha, epsilon):\n",
    "    \n",
    "    def FGSM(input_data, alpha, epsilon, data_grad):\n",
    "        noise = alpha * (universal_max - universal_min) * data_grad.sign()\n",
    "        eps = epsilon * (universal_max - universal_min)\n",
    "        noise = torch.clamp(noise, -eps, eps)\n",
    "        pert = input_data + noise\n",
    "        pert = torch.clamp(pert, universal_min, universal_max)\n",
    "        return pert\n",
    "\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    for data_batch, target_batch in test_loader:    # Batch Processing\n",
    "        for i in range(data_batch.size()[0]):\n",
    "            pert, target = data_batch[i].unsqueeze(0), target_batch[i].unsqueeze(0)\n",
    "            pert.requires_grad = True\n",
    "            data = pert\n",
    "            \n",
    "            output = model(pert)                                        # Output before PGD Attack\n",
    "            fore_pred = output.data.max(1, keepdim=True)[1]\n",
    "            if fore_pred.item() != target.item(): continue              # Already failed prediction, discard\n",
    "            \n",
    "            noise = torch.zeros(pert.shape).type_as(pert)\n",
    "            for iteration in range(k):\n",
    "                pert = pert + torch.Tensor(np.random.uniform(-epsilon,epsilon,pert.shape)).type_as(pert)   # Cannot use \"+=\"\n",
    "                pert.retain_grad()\n",
    "                pred = model(pert)\n",
    "                loss = loss_func_test(pred, target)\n",
    "                \n",
    "                model.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                pert_grad = pert.grad.data\n",
    "                pert = FGSM(pert, alpha, epsilon, pert_grad)        # The single step of PGD Attack is an FGSM Attack               \n",
    "                \n",
    "            output = model(pert)\n",
    "            post_pred = output.max(1, keepdim=True)[1]              # Output after the FGSM Attack\n",
    "            if post_pred.item() == target.item():\n",
    "                correct += 1\n",
    "            else:\n",
    "                if len(adv_examples) < 5:\n",
    "                    example = pert.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "            if (epsilon == 0 or alpha == 0) and (len(adv_examples) < 5):\n",
    "                            # Preparation for the following visualization, taking eps=0 into account\n",
    "                example = pert.squeeze().detach().cpu().numpy()\n",
    "                adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "\n",
    "    final_acc = correct/(float(len(test_loader.dataset)))\n",
    "    print(\"Alpha: {}\\tTest Accuracy = {} / {} = {:.2f}%\".format(alpha, correct, len(test_loader.dataset), final_acc*100.))\n",
    "\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "for i in range(len(epsilons)):\n",
    "    start = time.time()\n",
    "    acc, expl = PGD(model, test_loader, steps, alphas[i], epsilons[i])\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Visualization of Adversial Samples\n",
    "The following visualization is based on the code given at https://pytorch.org/tutorials/beginner/fgsm_tutorial.html?highlight=fgsm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Alpha: {}\".format(alphas[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, accuracies, color='#ff9999',linewidth=3)\n",
    "#ax1.scatter(test_cnt, test_loss, color='red')\n",
    "plt.legend(['Step=5, Alpha=Epsilon/step'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_acc = accuracies\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, fgsm_acc, color='#ff9999',linewidth=3)\n",
    "plt.plot(epsilons, pgd_acc, color='#7e9ecd',linewidth=3)\n",
    "plt.legend(['FGSM','PGD (step=5)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Different Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "steps = [2, 5, 8, 10, 20, 40]\n",
    "\n",
    "for stp in steps:\n",
    "    start = time.time()\n",
    "    acc, expl = PGD(model, test_loader, int(stp), 0.15 / stp, 0.15)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,2))\n",
    "for i in range(len(steps)):\n",
    "    plt.subplot(1,len(steps),i+1)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.xlabel(\"Steps: {}\".format(steps[i]), fontsize=14)\n",
    "    orig,adv,ex = examples[i][0]\n",
    "    plt.title(\"{} -> {}\".format(orig, adv))\n",
    "    plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(steps)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(steps),len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Steps: {}\".format(steps[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(steps, accuracies, color='#7e9ecd',linewidth=3)\n",
    "plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 PGD with Carlini-Wagner Loss\n",
    "It is obvious that an adversial sample generated with a smaller distance to the original data and a larger probability in mistaken category is better.  \n",
    "Therefore, we can rewrite the form of loss function to further enpower the attack.  \n",
    "Nevertheless, previous work has already covered this idea, known as **CW**.  \\\n",
    "Moreover, the idea of PGD with CW loss is already given in the original paper proposing PGD.  \n",
    "\n",
    "#### 2.3.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "constant = 1e-4\n",
    "steps = 5\n",
    "kappa = 0\n",
    "epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 CW-Loss Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cw(data, pert, pred, target, kappa, constant):\n",
    "    target_mask = torch.eye(len(pred[0]))[target].float()\n",
    "    correct_cat = torch.masked_select(pred, target_mask.bool())\n",
    "    wrong_cat = torch.argmax((1 - target_mask) * pred, dim=1).float()\n",
    "    f_cw = torch.clamp(-correct_cat + wrong_cat, min=kappa*(universal_max-universal_min))\n",
    "    loss = nn.MSELoss(reduction='sum')(pert, data) + torch.sum(constant*f_cw)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD_cw(model, test_loader, k, alpha, epsilon, kappa, constant):\n",
    "    \n",
    "    def FGSM(input_data, alpha, epsilon, data_grad):\n",
    "        noise = alpha * (universal_max - universal_min) * data_grad.sign()\n",
    "        eps = epsilon * (universal_max - universal_min)\n",
    "        noise = torch.clamp(noise, -eps, eps)\n",
    "        pert = input_data + noise\n",
    "        pert = torch.clamp(pert, universal_min, universal_max)\n",
    "        return pert\n",
    "\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    for data_batch, target_batch in test_loader:    # Batch Processing\n",
    "        for i in range(data_batch.size()[0]):\n",
    "            pert, target = data_batch[i].unsqueeze(0), target_batch[i].unsqueeze(0)\n",
    "            pert.requires_grad = True\n",
    "            data = pert\n",
    "            \n",
    "            output = model(pert)                                        # Output before PGD Attack\n",
    "            fore_pred = output.data.max(1, keepdim=True)[1]\n",
    "            if fore_pred.item() != target.item(): continue              # Already failed prediction, discard\n",
    "            \n",
    "            noise = torch.zeros(pert.shape).type_as(pert)\n",
    "            for iteration in range(k):\n",
    "                pert = pert + torch.Tensor(np.random.uniform(-epsilon,epsilon,pert.shape)).type_as(pert)   # Cannot use \"+=\"\n",
    "                pert.retain_grad()\n",
    "                pred = model(pert)\n",
    "                loss = loss_cw(data, pert, pred, target, kappa, constant)\n",
    "                \n",
    "                model.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                pert_grad = pert.grad.data\n",
    "                pert = FGSM(pert, alpha, epsilon, pert_grad)        # The single step of PGD Attack is an FGSM Attack               \n",
    "                \n",
    "            output = model(pert)\n",
    "            post_pred = output.max(1, keepdim=True)[1]              # Output after the FGSM Attack\n",
    "            if post_pred.item() == target.item():\n",
    "                correct += 1\n",
    "                if len(adv_examples) < 5:\n",
    "                    example = pert.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "            if (epsilon == 0 or alpha == 0) and (len(adv_examples) < 5):\n",
    "                            # Preparation for the following visualization, taking eps=0 into account\n",
    "                example = pert.squeeze().detach().cpu().numpy()\n",
    "                adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "\n",
    "    final_acc = correct/(float(len(test_loader.dataset)))\n",
    "    print(\"Alpha: {}\\tTest Accuracy = {} / {} = {:.2f}%\".format(alpha, correct, len(test_loader.dataset), final_acc*100.))\n",
    "\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 CW-Loss PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "alphas = np.divide(epsilons,steps)\n",
    "\n",
    "for i in range(len(epsilons)):\n",
    "    start = time.time()\n",
    "    acc, expl = PGD_cw(model, test_loader, steps, alphas[i], epsilons[i], kappa, constant)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Visualization of Adversial Samples\n",
    "The following visualization is based on the code given at https://pytorch.org/tutorials/beginner/fgsm_tutorial.html?highlight=fgsm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cw_acc = accuracies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, cw_acc, color='#ff9999',linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,2))\n",
    "for i in range(len(kappas)):\n",
    "    plt.subplot(1,len(kappas),i+1)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.xlabel(\"Kappa: {}\".format(kappas[i]), fontsize=14)\n",
    "    orig,adv,ex = examples[i][0]\n",
    "    plt.title(\"{} -> {}\".format(orig, adv))\n",
    "    plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "steps = [2, 5, 8, 10, 20, 40]\n",
    "\n",
    "for stp in steps:\n",
    "    start = time.time()\n",
    "    acc, expl = PGD_cw(model, test_loader, int(stp), 0.15 / stp, 0.15, 0, constant)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(steps)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(steps)+1,len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Steps: {}\".format(steps[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(steps, accuracies, color='#ff9999',linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(steps, pgdstp_acc, color='#ff9999',linewidth=3)\n",
    "plt.plot(steps, accuracies, color='#7e9ecd',linewidth=3)\n",
    "plt.legend(['PGD','PGD with CW Loss'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "constants = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "for cons in constants:\n",
    "    start = time.time()\n",
    "    acc, expl = PGD_cw(model, test_loader, 10, 0.15 / stp, 0.15, 0, cons)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(constants)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(7,len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Const: {}\".format(constants[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot([1e-4,1e-3,1e-2], accuracies, color='#ff9999',linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Constant')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 FGM, PGD with Different Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, 0.1, 0.2, 0.3, 0.6, 0.9, 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 FGEM: Fast Gradient Exponential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_exp(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * (universal_max - universal_min) * torch.exp(data_grad)\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_mul(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * (universal_max - universal_min) / data_grad\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_absexp(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * (universal_max - universal_min) * torch.exp(torch.abs(data_grad))\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_leap(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * (universal_max - universal_min) * (func.leaky_relu(data_grad.sign()) + 1)\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 FGM and PGD Based on Stair Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stairs(x):\n",
    "    y = np.multiply(np.array(x>.5, dtype=np.int), 1)\n",
    "    y = y + np.multiply(np.array(x>.2, dtype=np.int), 0.5)\n",
    "    y = y + np.multiply(np.array(x>0, dtype=np.int), 0.25)\n",
    "    y = y + np.multiply(np.array(x<0, dtype=np.int), -0.25)\n",
    "    y = y + np.multiply(np.array(x<-.2, dtype=np.int),-1)\n",
    "    return torch.Tensor(y)\n",
    "\n",
    "def FGSM_stairs(input_data, epsilon, data_grad):\n",
    "    pert = input_data + epsilon * (universal_max - universal_min) * stairs(data_grad.detach().numpy())\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "x = np.linspace(-0.5, 0.75, 500)\n",
    "y = stairs(x)\n",
    "\n",
    "plt.plot(x, y, linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Test of FGEM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    start = time.time()\n",
    "    acc, expl = FGSM_test(model, test_loader, eps, FGSM_exp)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, accuracies, color='#ff9999',linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.4 Test on FGM Attack Based on Stair Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "epsilons = [0, 0.1, 0.3,0.6, 0.9, 1.2]\n",
    "\n",
    "for eps in epsilons:\n",
    "    start = time.time()\n",
    "    acc, expl = FGSM_test(model, test_loader, eps, FGSM_stairs)\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(7,len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.5 Test on PGD Based on Stair Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "alphas = np.divide(epsilons, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD_single(input_data, alpha, epsilon, data_grad):\n",
    "    noise = alpha * (universal_max - universal_min) * (stairs(data_grad))\n",
    "    eps = epsilon * (universal_max - universal_min)\n",
    "    noise = torch.clamp(noise, -eps, eps)\n",
    "    pert = input_data + noise\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert\n",
    "\n",
    "def PGD(model, test_loader, k, alpha, epsilon):\n",
    "\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    ori_examples = []\n",
    "\n",
    "    for data_batch, target_batch in test_loader:    # Batch Processing\n",
    "        for i in range(data_batch.size()[0]):\n",
    "            pert, target = data_batch[i].unsqueeze(0), target_batch[i].unsqueeze(0)\n",
    "            pert.requires_grad = True\n",
    "            data = pert\n",
    "            \n",
    "            output = model(pert)                                        # Output before PGD Attack\n",
    "            fore_pred = output.data.max(1, keepdim=True)[1]\n",
    "            if fore_pred.item() != target.item(): continue              # Already failed prediction, discard\n",
    "            \n",
    "            noise = torch.zeros(pert.shape).type_as(pert)\n",
    "            for iteration in range(k):\n",
    "                pert = pert + torch.Tensor(np.random.uniform(-epsilon,epsilon,pert.shape)).type_as(pert)   # Cannot use \"+=\"\n",
    "                pert.retain_grad()\n",
    "                pred = model(pert)\n",
    "                loss = loss_func_test(pred, target)\n",
    "                \n",
    "                model.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                pert_grad = pert.grad.data\n",
    "                pert = PGD_single(pert, alpha, epsilon, pert_grad)        # The single step of PGD Attack is an FGSM Attack               \n",
    "                \n",
    "            output = model(pert)\n",
    "            post_pred = output.max(1, keepdim=True)[1]              # Output after the FGSM Attack\n",
    "            if post_pred.item() == target.item():\n",
    "                correct += 1\n",
    "            else:\n",
    "                if len(adv_examples) < 5:\n",
    "                    example = pert.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "            if (epsilon == 0 or alpha == 0) and (len(adv_examples) < 5):\n",
    "                            # Preparation for the following visualization, taking eps=0 into account\n",
    "                example = pert.squeeze().detach().cpu().numpy()\n",
    "                adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "                example = data.squeeze().detach().cpu().numpy()\n",
    "                ori_examples += [example]\n",
    "\n",
    "    final_acc = correct/(float(len(test_loader.dataset)))\n",
    "    print(\"Alpha: {}\\tTest Accuracy = {} / {} = {:.2f}%\".format(alpha, correct, len(test_loader.dataset), final_acc*100.))\n",
    "\n",
    "    return final_acc, adv_examples, ori_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "original = []\n",
    "\n",
    "for i in range(len(epsilons)):\n",
    "    start = time.time()\n",
    "    acc, expl, orig = PGD(model, test_loader, steps, alphas[i], epsilons[i])\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    original += [orig]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(7,len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Alpha: {}\".format(alphas[i]*2), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "        #plt.imshow(original[i][j], cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, accuracies, color='#7e9ecd',linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.6 Test on i-FGEM (iteration-FGEM) Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "alphas = np.divide(epsilons, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD_single(input_data, alpha, epsilon, data_grad):\n",
    "    noise = alpha * (universal_max - universal_min) * (torch.exp(data_grad))\n",
    "    eps = epsilon * (universal_max - universal_min)\n",
    "    noise = torch.clamp(noise, -eps, eps)\n",
    "    pert = input_data + noise\n",
    "    pert = torch.clamp(pert, universal_min, universal_max)\n",
    "    return pert\n",
    "\n",
    "def PGD(model, test_loader, k, alpha, epsilon):\n",
    "\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    ori_examples = []\n",
    "\n",
    "    for data_batch, target_batch in test_loader:    # Batch Processing\n",
    "        for i in range(data_batch.size()[0]):\n",
    "            pert, target = data_batch[i].unsqueeze(0), target_batch[i].unsqueeze(0)\n",
    "            pert.requires_grad = True\n",
    "            data = pert\n",
    "            \n",
    "            output = model(pert)                                        # Output before PGD Attack\n",
    "            fore_pred = output.data.max(1, keepdim=True)[1]\n",
    "            if fore_pred.item() != target.item(): continue              # Already failed prediction, discard\n",
    "            \n",
    "            noise = torch.zeros(pert.shape).type_as(pert)\n",
    "            for iteration in range(k):\n",
    "                #pert = pert + torch.Tensor(np.random.uniform(-epsilon,epsilon,pert.shape)).type_as(pert)   # Cannot use \"+=\"\n",
    "                pert.retain_grad()\n",
    "                pred = model(pert)\n",
    "                loss = loss_func_test(pred, target)\n",
    "                \n",
    "                model.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                pert_grad = pert.grad.data\n",
    "                pert = PGD_single(pert, alpha, epsilon, pert_grad)        # The single step of PGD Attack is an FGSM Attack               \n",
    "                \n",
    "            output = model(pert)\n",
    "            post_pred = output.max(1, keepdim=True)[1]              # Output after the FGSM Attack\n",
    "            if post_pred.item() == target.item():\n",
    "                correct += 1\n",
    "            else:\n",
    "                if len(adv_examples) < 5:\n",
    "                    example = pert.squeeze().detach().cpu().numpy()\n",
    "                    adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "            if (epsilon == 0 or alpha == 0) and (len(adv_examples) < 5):\n",
    "                            # Preparation for the following visualization, taking eps=0 into account\n",
    "                example = pert.squeeze().detach().cpu().numpy()\n",
    "                adv_examples += [(fore_pred.item(), post_pred.item(), example)]\n",
    "                example = data.squeeze().detach().cpu().numpy()\n",
    "                ori_examples += [example]\n",
    "\n",
    "    final_acc = correct/(float(len(test_loader.dataset)))\n",
    "    print(\"Alpha: {}\\tTest Accuracy = {} / {} = {:.2f}%\".format(alpha, correct, len(test_loader.dataset), final_acc*100.))\n",
    "\n",
    "    return final_acc, adv_examples, ori_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "original = []\n",
    "\n",
    "for i in range(len(epsilons)):\n",
    "    start = time.time()\n",
    "    acc, expl, orig = PGD(model, test_loader, steps, alphas[i], epsilons[i])\n",
    "    accuracies += [acc]\n",
    "    examples += [expl]\n",
    "    original += [orig]\n",
    "    end = time.time()\n",
    "    print(\"Execution Time: %s ms\" % ((end-start)*1000),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,12))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(7,len(examples[i]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Alpha: {}\".format(alphas[i]*2), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "        #plt.imshow(original[i][j], cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(epsilons, accuracies, color='#7e9ecd',linewidth=3)\n",
    "#plt.legend(['PGD (Epsilon=0.15)'], loc='upper right')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adversarial Defence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defence(CNN):\n",
    "    def __init__(self):\n",
    "        super(Defence,self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defence_k = 3\n",
    "defence_epsilon = 0.05\n",
    "defence_learning_rate = 0.005\n",
    "defence_epochs = 3\n",
    "defence_model = Defence_CNN()\n",
    "defence_criterion = F.nll_loss\n",
    "defence_optimizer = optim.Adam(defence_model.parameters(),lr=defence_learning_rate)\n",
    "defence_iter_optimizer = optim.Adam(defence_model.parameters(),lr=0.1*defence_learning_rate)\n",
    "defence_scheduler = StepLR(defence_optimizer,step_size=50,gamma=0.8)\n",
    "defence_iter_scheduler = StepLR(defence_iter_optimizer,step_size=50,gamma=0.8)\n",
    "defence_loss_record = list()\n",
    "defence_accuracy_record = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defence_train(model,train_data,k,epsilon,epoch):\n",
    "    model.train()\n",
    "    correct=0\n",
    "    for batch,(data,target) in enumerate(train_data):\n",
    "        data.requires_grad = True\n",
    "        for i in range(k-1):\n",
    "            data.retain_grad()\n",
    "            defence_iter_optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            data_temp = data + torch.Tensor(np.random.uniform(-epsilon,epsilon,data.shape))\n",
    "            result = model(data_temp)\n",
    "            defence_train_loss = defence_criterion(result,target)\n",
    "            defence_train_loss.backward(retain_graph=True)\n",
    "            data_grad = data.grad.data\n",
    "            data = FGSM(data_temp,epsilon,data_grad)\n",
    "            defence_iter_optimizer.step()\n",
    "        data_temp = data + torch.Tensor(np.random.uniform(-epsilon,epsilon,data.shape))\n",
    "        defence_optimizer.zero_grad()\n",
    "        result = model(data_temp)\n",
    "        defence_train_loss = defence_criterion(result,target)\n",
    "        defence_train_loss.backward(retain_graph=True)\n",
    "        pred=result.argmax(dim=1,keepdim=True)\n",
    "        accuracy = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += accuracy\n",
    "        defence_loss_record.append(defence_train_loss.item())\n",
    "        defence_accuracy_record.append(accuracy / len(data))\n",
    "        defence_optimizer.step()\n",
    "        if(batch%10 == 0):\n",
    "            print(\"Denfence Train Epoch{} : [ {}/{} ({:.0f}%) ]\\nLoss:{:.6f}\\tAccuracy: {}/{} ({:.2f}%)\".format(\n",
    "                epoch+1,batch*len(data),len(train_data.dataset),\n",
    "                100.*batch*len(data)/len(train_data.dataset),defence_train_loss.item(),\n",
    "                correct,10*len(data),100.*correct/(10*len(data))))\n",
    "            correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defence_test(model,test_data,k,epsilon):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for batch,(data,target) in enumerate(test_data):\n",
    "        data.requires_grad = True\n",
    "        for i in range(k-1):\n",
    "            data.retain_grad()\n",
    "            data_temp = data + torch.Tensor(np.random.uniform(-epsilon,epsilon,data.shape))\n",
    "            model.zero_grad()\n",
    "            result = model(data_temp)\n",
    "            defence_test_loss = defence_criterion(result,target)\n",
    "            defence_test_loss.backward(retain_graph=True)\n",
    "            data_grad = data.grad.data\n",
    "            data = FGSM(data_temp,epsilon,data_grad)\n",
    "        with torch.no_grad():\n",
    "            data_temp = data+torch.Tensor(np.random.uniform(-epsilon,epsilon,data.shape))\n",
    "            result = model(data)\n",
    "            defence_test_loss = defence_criterion(result,target)\n",
    "            pred = result.argmax(dim=1,keepdim=True)\n",
    "            accuracy = pred.eq(target.view_as(pred)).sum().item()\n",
    "            correct += accuracy\n",
    "            loss += defence_test_loss.item()\n",
    "        loss /= len(test_data.dataset)\n",
    "    print(\"Test Set: Average Loss:{:.6f} Accuracy:{}/{}({:.2f}%)\".format(\n",
    "        loss,correct,\n",
    "        len(test_data.dataset),\n",
    "        100.*correct/len(test_data.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(defence_epochs):\n",
    "    defence_train(defence_model,train_data,defence_k,defence_epsilon,epoch)\n",
    "    defence_test(defence_model,test_data,defence_k,defence_epsilon)\n",
    "    defence_iter_scheduler.step()\n",
    "    defence_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. License\n",
    "The codes above had referrences to following sources:  \n",
    "1. https://zhuanlan.zhihu.com/p/137571225 **[Section 1]**  \n",
    "2. https://pytorch.org/tutorials/beginner/fgsm_tutorial.html?highlight=fgsm **[Section 2.1]**  \n",
    "3. https://blog.csdn.net/weixin_41712499/article/details/110878322 **[Section 2.1+2.2]**  \n",
    "4. https://www.cnblogs.com/tangweijqxx/p/10617752.html **[Section 2.2]**  \n",
    "5. https://arxiv.org/pdf/1607.02533v4.pdf **[Section 2.2]**\n",
    "6. https://www.cnblogs.com/tangweijqxx/p/10627360.html **[Section 2.3]**  \n",
    "7. https://arxiv.org/pdf/1706.06083.pdf (original paper of PGD) **[Section 2.3]**  \n",
    "8. https://arxiv.org/pdf/1608.04644.pdf (original paper of CW) **[Section 2.3]**  \n",
    "9. https://arxiv.org/pdf/1412.6572v2.pdf (original paper of FGSM) **[Section 2.4]**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
